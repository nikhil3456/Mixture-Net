{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from random import sample\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn import metrics\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "# from cgcnn.data import CIFData\n",
    "# from cgcnn.data import collate_pool, get_train_val_test_loader\n",
    "from cgcnn.featureModel import CrystalGraphConvNet\n",
    "from property_prediction_ofm.model import Net\n",
    "\n",
    "from dataloader import CIFOFMData\n",
    "from dataloader import collate_pool, get_train_val_test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class MixtureNet(nn.Module):\n",
    "    def __init__(self, input_size=64):\n",
    "        super(MixtureNet, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, 48)\n",
    "        self.fc2 = nn.Linear(48, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MixtureNet(\n",
       "  (fc1): Linear(in_features=64, out_features=48, bias=True)\n",
       "  (fc2): Linear(in_features=48, out_features=32, bias=True)\n",
       "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixnet = MixtureNet()\n",
    "mixnet = mixnet.float()\n",
    "mixnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_options = '../project_mlns/dataset/'\n",
    "modelpathCG = 'trained_nets/formation-energy-per-atom.pth.tar'\n",
    "modelpathOFM = 'trained_nets/propertyPredictionUsingOFM_net.pth'\n",
    "\n",
    "workers = 0\n",
    "epochs = 30\n",
    "start_epoch = 0\n",
    "batch_size = 32\n",
    "lr = 0.01\n",
    "lr_milestones = [100]\n",
    "disable_cuda = False\n",
    "\n",
    "momentum = 0.9\n",
    "weight_decay = 0\n",
    "print_freq = 10\n",
    "\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "optim_type ='SGD'\n",
    "\n",
    "cuda = not disable_cuda and torch.cuda.is_available()\n",
    "\n",
    "best_mae_error = 1e10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] train_ratio is None, using all training data.\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "dataset = CIFOFMData(data_options)\n",
    "collate_fn = collate_pool\n",
    "train_loader, val_loader, test_loader = get_train_val_test_loader(\n",
    "    dataset=dataset,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=cuda,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=workers,\n",
    "    train_size = None,\n",
    "    test_size = None,\n",
    "    val_size = None,\n",
    "    val_ratio=val_ratio,\n",
    "    test_ratio=test_ratio,\n",
    "    return_test=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalizer(object):\n",
    "    \"\"\"Normalize a Tensor and restore it later. \"\"\"\n",
    "\n",
    "    def __init__(self, tensor):\n",
    "        \"\"\"tensor is taken as a sample to calculate the mean and std\"\"\"\n",
    "        self.mean = torch.mean(tensor)\n",
    "        self.std = torch.std(tensor)\n",
    "\n",
    "    def norm(self, tensor):\n",
    "        return (tensor - self.mean) / self.std\n",
    "\n",
    "    def denorm(self, normed_tensor):\n",
    "        return normed_tensor * self.std + self.mean\n",
    "\n",
    "    def state_dict(self):\n",
    "        return {'mean': self.mean,\n",
    "                'std': self.std}\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.mean = state_dict['mean']\n",
    "        self.std = state_dict['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(dataset) < 500:\n",
    "    warnings.warn('Dataset has less than 500 data points. '\n",
    "                  'Lower accuracy is expected. ')\n",
    "    sample_data_list = [dataset[i] for i in range(len(dataset))]\n",
    "else:\n",
    "    sample_data_list = [dataset[i] for i in\n",
    "                        sample(range(len(dataset)), 500)]\n",
    "_, sample_target, _, _ = collate_pool(sample_data_list)\n",
    "normalizer = Normalizer(sample_target)\n",
    "\n",
    "# build models\n",
    "structures, _, _, _ = dataset[0]\n",
    "orig_atom_fea_len = structures[0].shape[-1]\n",
    "nbr_fea_len = structures[1].shape[-1]\n",
    "\n",
    "model_checkpoint = torch.load(modelpathCG,\n",
    "                              map_location=lambda storage, loc: storage)\n",
    "model_args = argparse.Namespace(**model_checkpoint['args'])\n",
    "modelCG = CrystalGraphConvNet(orig_atom_fea_len, nbr_fea_len,\n",
    "                            atom_fea_len=model_args.atom_fea_len,\n",
    "                            n_conv=model_args.n_conv,\n",
    "                            h_fea_len=model_args.h_fea_len,\n",
    "                            n_h=model_args.n_h,\n",
    "                            classification=False)\n",
    "\n",
    "modelOFM = Net()\n",
    "modelOFM.load_state_dict(torch.load(modelpathOFM))\n",
    "\n",
    "if cuda:\n",
    "    modelOFM.cuda()\n",
    "    modelCG.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss func and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "if optim_type == 'SGD':\n",
    "    optimizer = optim.SGD(mixnet.parameters(), lr,\n",
    "                          momentum=momentum,\n",
    "                          weight_decay=weight_decay)\n",
    "elif optim_type == 'Adam':\n",
    "    optimizer = optim.Adam(mixnet.parameters(), lr,\n",
    "                           weight_decay=weight_decay)\n",
    "else:\n",
    "    raise NameError('Only SGD or Adam is allowed as --optim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resume from a checkpoint\n",
    "checkpointCG = torch.load(modelpathCG)\n",
    "modelCG.load_state_dict(checkpointCG['state_dict'])\n",
    "normalizer.load_state_dict(checkpointCG['normalizer'])\n",
    "\n",
    "checkpointOFM = torch.load(modelpathOFM)\n",
    "modelOFM.load_state_dict(checkpointOFM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(prediction, target):\n",
    "    \"\"\"\n",
    "    Computes the mean absolute error between prediction and target\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    prediction: torch.Tensor (N, 1)\n",
    "    target: torch.Tensor (N, 1)\n",
    "    \"\"\"\n",
    "    return torch.mean(torch.abs(target - prediction))\n",
    "\n",
    "\n",
    "def class_eval(prediction, target):\n",
    "    prediction = np.exp(prediction.numpy())\n",
    "    target = target.numpy()\n",
    "    pred_label = np.argmax(prediction, axis=1)\n",
    "    target_label = np.squeeze(target)\n",
    "    if not target_label.shape:\n",
    "        target_label = np.asarray([target_label])\n",
    "    if prediction.shape[1] == 2:\n",
    "        precision, recall, fscore, _ = metrics.precision_recall_fscore_support(\n",
    "            target_label, pred_label, average='binary')\n",
    "        auc_score = metrics.roc_auc_score(target_label, prediction[:, 1])\n",
    "        accuracy = metrics.accuracy_score(target_label, pred_label)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return accuracy, precision, recall, fscore, auc_score\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, k):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every k epochs\"\"\"\n",
    "    assert type(k) is int\n",
    "    lr = args.lr * (0.1 ** (epoch // k))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, mixnet, modelCG, modelOFM, criterion, optimizer, epoch, normalizer):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    mae_errors = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    mixnet.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target, _, ofmMat) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if cuda:\n",
    "            input_var = (Variable(input[0].cuda(non_blocking=True)),\n",
    "                         Variable(input[1].cuda(non_blocking=True)),\n",
    "                         input[2].cuda(non_blocking=True),\n",
    "                         [crys_idx.cuda(non_blocking=True) for crys_idx in input[3]])\n",
    "            inOfmMat = ofmMat.float().cuda(non_blocking=True)\n",
    "        else:\n",
    "            input_var = (Variable(input[0]),\n",
    "                         Variable(input[1]),\n",
    "                         input[2],\n",
    "                         input[3])\n",
    "            inOfmMat = ofmMat.float()\n",
    "            \n",
    "        # normalize target\n",
    "        target_normed = normalizer.norm(target)\n",
    "        \n",
    "        if cuda:\n",
    "            target_var = Variable(target_normed.cuda(non_blocking=True))\n",
    "        else:\n",
    "            target_var = Variable(target_normed)\n",
    "\n",
    "        # compute feature from CG and OFM models\n",
    "        featureCG = modelCG(*input_var)\n",
    "        featureOFM = modelOFM(inOfmMat)\n",
    "        # print(featureCG.size(), featureOFM.size())   \n",
    "        # final feature after concatenation of features from CG and OFM models\n",
    "        feature = torch.cat((featureCG, featureOFM), 1)\n",
    "        # print(feature.size())\n",
    "        output = mixnet(feature)\n",
    "        \n",
    "        loss = criterion(output, target_var)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        mae_error = mae(normalizer.denorm(output.data.cpu()), target)\n",
    "        losses.update(loss.data.cpu(), target.size(0))\n",
    "        mae_errors.update(mae_error, target.size(0))\n",
    "       \n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'MAE {mae_errors.val:.3f} ({mae_errors.avg:.3f})'.format(\n",
    "                epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                data_time=data_time, loss=losses, mae_errors=mae_errors)\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/81]\tTime 0.543 (0.543)\tData 0.520 (0.520)\tLoss 61.2409 (61.2409)\tMAE 5.960 (5.960)\n",
      "Epoch: [0][10/81]\tTime 0.558 (0.603)\tData 0.513 (0.575)\tLoss 42.9800 (176.1419)\tMAE 5.842 (8.076)\n",
      "Epoch: [0][20/81]\tTime 0.440 (0.640)\tData 0.414 (0.608)\tLoss 77.0584 (203.3968)\tMAE 8.430 (8.841)\n",
      "Epoch: [0][30/81]\tTime 0.735 (0.618)\tData 0.710 (0.587)\tLoss 139.5190 (181.5776)\tMAE 8.037 (8.578)\n",
      "Epoch: [0][40/81]\tTime 0.654 (0.627)\tData 0.626 (0.597)\tLoss 310.3209 (180.6172)\tMAE 10.625 (8.446)\n",
      "Epoch: [0][50/81]\tTime 0.509 (0.626)\tData 0.482 (0.597)\tLoss 82.6150 (189.8645)\tMAE 7.905 (8.439)\n",
      "Epoch: [0][60/81]\tTime 0.424 (0.619)\tData 0.399 (0.590)\tLoss 88.0301 (196.7016)\tMAE 7.729 (8.512)\n",
      "Epoch: [0][70/81]\tTime 0.547 (0.619)\tData 0.523 (0.590)\tLoss 254.7070 (211.8556)\tMAE 11.607 (8.611)\n",
      "Epoch: [0][80/81]\tTime 0.110 (0.613)\tData 0.082 (0.585)\tLoss 18.6608 (208.8024)\tMAE 3.965 (8.573)\n",
      "Epoch: [1][0/81]\tTime 0.041 (0.041)\tData 0.009 (0.009)\tLoss 1078.2468 (1078.2468)\tMAE 17.152 (17.152)\n",
      "Epoch: [1][10/81]\tTime 0.028 (0.034)\tData 0.003 (0.005)\tLoss 87.0365 (319.3040)\tMAE 7.774 (9.450)\n",
      "Epoch: [1][20/81]\tTime 0.046 (0.040)\tData 0.008 (0.005)\tLoss 153.0331 (253.9424)\tMAE 8.811 (9.229)\n",
      "Epoch: [1][30/81]\tTime 0.044 (0.041)\tData 0.006 (0.006)\tLoss 49.3627 (209.8369)\tMAE 5.748 (8.524)\n",
      "Epoch: [1][40/81]\tTime 0.045 (0.042)\tData 0.006 (0.006)\tLoss 729.4084 (194.0284)\tMAE 11.461 (8.154)\n",
      "Epoch: [1][50/81]\tTime 0.045 (0.043)\tData 0.007 (0.006)\tLoss 26.5094 (200.5897)\tMAE 5.024 (8.143)\n",
      "Epoch: [1][60/81]\tTime 0.044 (0.043)\tData 0.005 (0.006)\tLoss 311.9219 (214.5182)\tMAE 11.243 (8.420)\n",
      "Epoch: [1][70/81]\tTime 0.049 (0.043)\tData 0.006 (0.006)\tLoss 44.8282 (213.1929)\tMAE 6.294 (8.548)\n",
      "Epoch: [1][80/81]\tTime 0.021 (0.043)\tData 0.001 (0.006)\tLoss 191.5264 (208.6974)\tMAE 12.214 (8.540)\n",
      "Epoch: [2][0/81]\tTime 0.043 (0.043)\tData 0.004 (0.004)\tLoss 86.2286 (86.2286)\tMAE 7.144 (7.144)\n",
      "Epoch: [2][10/81]\tTime 0.044 (0.045)\tData 0.006 (0.006)\tLoss 42.0591 (195.5767)\tMAE 6.053 (8.368)\n",
      "Epoch: [2][20/81]\tTime 0.045 (0.045)\tData 0.006 (0.006)\tLoss 81.3898 (161.1441)\tMAE 5.741 (7.708)\n",
      "Epoch: [2][30/81]\tTime 0.044 (0.045)\tData 0.006 (0.006)\tLoss 161.3001 (175.3507)\tMAE 8.719 (8.092)\n",
      "Epoch: [2][40/81]\tTime 0.045 (0.045)\tData 0.006 (0.006)\tLoss 971.6922 (216.0389)\tMAE 13.795 (8.644)\n",
      "Epoch: [2][50/81]\tTime 0.044 (0.045)\tData 0.005 (0.006)\tLoss 71.7391 (225.4186)\tMAE 8.263 (8.868)\n",
      "Epoch: [2][60/81]\tTime 0.036 (0.044)\tData 0.006 (0.006)\tLoss 301.5803 (228.2796)\tMAE 9.725 (8.969)\n",
      "Epoch: [2][70/81]\tTime 0.027 (0.043)\tData 0.003 (0.006)\tLoss 40.4675 (220.9255)\tMAE 5.631 (8.829)\n",
      "Epoch: [2][80/81]\tTime 0.019 (0.041)\tData 0.001 (0.006)\tLoss 69.5188 (208.3805)\tMAE 8.105 (8.611)\n",
      "Epoch: [3][0/81]\tTime 0.046 (0.046)\tData 0.003 (0.003)\tLoss 639.2714 (639.2714)\tMAE 11.471 (11.471)\n",
      "Epoch: [3][10/81]\tTime 0.029 (0.039)\tData 0.004 (0.006)\tLoss 248.5847 (253.7128)\tMAE 10.372 (8.933)\n",
      "Epoch: [3][20/81]\tTime 0.028 (0.034)\tData 0.004 (0.005)\tLoss 35.6231 (225.8502)\tMAE 5.696 (8.489)\n",
      "Epoch: [3][30/81]\tTime 0.026 (0.032)\tData 0.003 (0.004)\tLoss 70.7911 (245.3866)\tMAE 6.738 (8.501)\n",
      "Epoch: [3][40/81]\tTime 0.029 (0.031)\tData 0.004 (0.004)\tLoss 63.8100 (224.8120)\tMAE 6.535 (8.383)\n",
      "Epoch: [3][50/81]\tTime 0.027 (0.030)\tData 0.002 (0.004)\tLoss 129.8584 (213.1928)\tMAE 7.549 (8.336)\n",
      "Epoch: [3][60/81]\tTime 0.028 (0.030)\tData 0.003 (0.004)\tLoss 51.7303 (209.9840)\tMAE 6.801 (8.370)\n",
      "Epoch: [3][70/81]\tTime 0.030 (0.029)\tData 0.003 (0.004)\tLoss 123.3624 (205.3262)\tMAE 7.308 (8.349)\n",
      "Epoch: [3][80/81]\tTime 0.016 (0.029)\tData 0.001 (0.004)\tLoss 93.2165 (209.3205)\tMAE 8.495 (8.431)\n",
      "Epoch: [4][0/81]\tTime 0.029 (0.029)\tData 0.003 (0.003)\tLoss 67.1532 (67.1532)\tMAE 7.222 (7.222)\n",
      "Epoch: [4][10/81]\tTime 0.028 (0.028)\tData 0.003 (0.003)\tLoss 149.9578 (280.3882)\tMAE 7.635 (9.429)\n",
      "Epoch: [4][20/81]\tTime 0.029 (0.028)\tData 0.003 (0.003)\tLoss 159.3329 (231.4020)\tMAE 8.034 (9.154)\n",
      "Epoch: [4][30/81]\tTime 0.028 (0.028)\tData 0.003 (0.003)\tLoss 43.7181 (199.5999)\tMAE 5.389 (8.528)\n",
      "Epoch: [4][40/81]\tTime 0.028 (0.028)\tData 0.003 (0.003)\tLoss 195.1375 (193.4563)\tMAE 10.138 (8.472)\n",
      "Epoch: [4][50/81]\tTime 0.029 (0.028)\tData 0.003 (0.003)\tLoss 212.4250 (186.7926)\tMAE 9.104 (8.362)\n",
      "Epoch: [4][60/81]\tTime 0.028 (0.028)\tData 0.004 (0.003)\tLoss 85.0577 (181.8415)\tMAE 7.912 (8.322)\n",
      "Epoch: [4][70/81]\tTime 0.027 (0.028)\tData 0.002 (0.003)\tLoss 326.6499 (200.8681)\tMAE 10.253 (8.436)\n",
      "Epoch: [4][80/81]\tTime 0.012 (0.028)\tData 0.000 (0.003)\tLoss 919.1020 (208.4683)\tMAE 22.111 (8.577)\n",
      "Epoch: [5][0/81]\tTime 0.028 (0.028)\tData 0.003 (0.003)\tLoss 179.9873 (179.9873)\tMAE 8.947 (8.947)\n",
      "Epoch: [5][10/81]\tTime 0.027 (0.028)\tData 0.003 (0.003)\tLoss 113.2972 (266.0193)\tMAE 8.757 (9.868)\n",
      "Epoch: [5][20/81]\tTime 0.028 (0.028)\tData 0.003 (0.003)\tLoss 79.0793 (312.1335)\tMAE 7.923 (10.600)\n",
      "Epoch: [5][30/81]\tTime 0.028 (0.028)\tData 0.003 (0.003)\tLoss 81.0868 (268.2350)\tMAE 6.705 (9.955)\n",
      "Epoch: [5][40/81]\tTime 0.028 (0.028)\tData 0.003 (0.003)\tLoss 223.1450 (244.1616)\tMAE 9.223 (9.573)\n",
      "Epoch: [5][50/81]\tTime 0.028 (0.029)\tData 0.003 (0.003)\tLoss 74.4384 (237.0697)\tMAE 6.891 (9.297)\n",
      "Epoch: [5][60/81]\tTime 0.028 (0.029)\tData 0.003 (0.003)\tLoss 53.0904 (208.1303)\tMAE 6.367 (8.814)\n",
      "Epoch: [5][70/81]\tTime 0.029 (0.029)\tData 0.004 (0.003)\tLoss 167.9299 (204.2636)\tMAE 7.753 (8.605)\n",
      "Epoch: [5][80/81]\tTime 0.016 (0.029)\tData 0.001 (0.003)\tLoss 38.9458 (208.8309)\tMAE 6.063 (8.677)\n",
      "Epoch: [6][0/81]\tTime 0.029 (0.029)\tData 0.003 (0.003)\tLoss 75.2753 (75.2753)\tMAE 7.893 (7.893)\n",
      "Epoch: [6][10/81]\tTime 0.029 (0.028)\tData 0.004 (0.004)\tLoss 111.8000 (143.6727)\tMAE 8.123 (8.383)\n",
      "Epoch: [6][20/81]\tTime 0.029 (0.028)\tData 0.003 (0.003)\tLoss 47.8198 (144.8666)\tMAE 5.903 (7.838)\n",
      "Epoch: [6][30/81]\tTime 0.030 (0.028)\tData 0.003 (0.003)\tLoss 57.7950 (192.7138)\tMAE 6.603 (8.039)\n",
      "Epoch: [6][40/81]\tTime 0.036 (0.030)\tData 0.008 (0.004)\tLoss 332.7976 (206.1011)\tMAE 9.373 (8.160)\n",
      "Epoch: [6][50/81]\tTime 0.027 (0.031)\tData 0.003 (0.005)\tLoss 72.1233 (209.7663)\tMAE 6.651 (8.321)\n",
      "Epoch: [6][60/81]\tTime 0.036 (0.032)\tData 0.008 (0.005)\tLoss 85.0833 (204.4536)\tMAE 7.615 (8.404)\n",
      "Epoch: [6][70/81]\tTime 0.036 (0.033)\tData 0.008 (0.005)\tLoss 262.1110 (212.0000)\tMAE 11.346 (8.581)\n",
      "Epoch: [6][80/81]\tTime 0.016 (0.033)\tData 0.001 (0.006)\tLoss 1484.6851 (208.7168)\tMAE 24.378 (8.618)\n",
      "Epoch: [7][0/81]\tTime 0.033 (0.033)\tData 0.006 (0.006)\tLoss 44.4885 (44.4885)\tMAE 6.179 (6.179)\n",
      "Epoch: [7][10/81]\tTime 0.035 (0.035)\tData 0.008 (0.008)\tLoss 46.1866 (208.3907)\tMAE 6.397 (8.384)\n",
      "Epoch: [7][20/81]\tTime 0.035 (0.035)\tData 0.007 (0.007)\tLoss 92.6756 (195.6649)\tMAE 7.075 (8.330)\n",
      "Epoch: [7][30/81]\tTime 0.036 (0.035)\tData 0.008 (0.007)\tLoss 39.7960 (210.4870)\tMAE 6.063 (8.422)\n",
      "Epoch: [7][40/81]\tTime 0.026 (0.034)\tData 0.002 (0.006)\tLoss 267.8778 (209.2898)\tMAE 9.107 (8.463)\n",
      "Epoch: [7][50/81]\tTime 0.026 (0.033)\tData 0.003 (0.006)\tLoss 56.0154 (210.0843)\tMAE 7.073 (8.507)\n",
      "Epoch: [7][60/81]\tTime 0.026 (0.032)\tData 0.003 (0.005)\tLoss 169.1122 (196.0497)\tMAE 7.914 (8.449)\n",
      "Epoch: [7][70/81]\tTime 0.035 (0.032)\tData 0.007 (0.005)\tLoss 28.5067 (200.3591)\tMAE 5.144 (8.473)\n",
      "Epoch: [7][80/81]\tTime 0.016 (0.032)\tData 0.001 (0.005)\tLoss 12.7562 (208.7525)\tMAE 2.621 (8.563)\n",
      "Epoch: [8][0/81]\tTime 0.034 (0.034)\tData 0.006 (0.006)\tLoss 177.6315 (177.6315)\tMAE 9.125 (9.125)\n",
      "Epoch: [8][10/81]\tTime 0.028 (0.035)\tData 0.003 (0.005)\tLoss 501.4842 (214.2730)\tMAE 11.547 (9.142)\n",
      "Epoch: [8][20/81]\tTime 0.035 (0.035)\tData 0.008 (0.005)\tLoss 95.2230 (217.4078)\tMAE 8.229 (8.892)\n",
      "Epoch: [8][30/81]\tTime 0.026 (0.034)\tData 0.002 (0.005)\tLoss 255.4307 (192.8090)\tMAE 9.379 (8.653)\n",
      "Epoch: [8][40/81]\tTime 0.030 (0.033)\tData 0.003 (0.005)\tLoss 79.0003 (192.1488)\tMAE 6.454 (8.506)\n",
      "Epoch: [8][50/81]\tTime 0.029 (0.032)\tData 0.003 (0.005)\tLoss 210.3221 (197.2679)\tMAE 10.168 (8.577)\n",
      "Epoch: [8][60/81]\tTime 0.029 (0.031)\tData 0.004 (0.004)\tLoss 770.1890 (209.6086)\tMAE 13.645 (8.667)\n",
      "Epoch: [8][70/81]\tTime 0.028 (0.031)\tData 0.004 (0.004)\tLoss 33.2028 (210.6902)\tMAE 5.579 (8.646)\n",
      "Epoch: [8][80/81]\tTime 0.011 (0.030)\tData 0.000 (0.004)\tLoss 35.2654 (208.6667)\tMAE 6.168 (8.598)\n",
      "Epoch: [9][0/81]\tTime 0.029 (0.029)\tData 0.003 (0.003)\tLoss 333.3673 (333.3673)\tMAE 11.336 (11.336)\n",
      "Epoch: [9][10/81]\tTime 0.028 (0.028)\tData 0.003 (0.003)\tLoss 478.5484 (280.2532)\tMAE 11.836 (8.864)\n",
      "Epoch: [9][20/81]\tTime 0.028 (0.028)\tData 0.003 (0.003)\tLoss 85.8673 (200.8564)\tMAE 6.741 (8.185)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][30/81]\tTime 0.024 (0.028)\tData 0.002 (0.003)\tLoss 450.8015 (201.3913)\tMAE 10.004 (8.251)\n",
      "Epoch: [9][40/81]\tTime 0.029 (0.028)\tData 0.004 (0.003)\tLoss 73.9308 (200.6547)\tMAE 6.745 (8.236)\n",
      "Epoch: [9][50/81]\tTime 0.029 (0.028)\tData 0.004 (0.003)\tLoss 168.8675 (196.9488)\tMAE 7.718 (8.334)\n",
      "Epoch: [9][60/81]\tTime 0.028 (0.028)\tData 0.004 (0.003)\tLoss 45.4854 (217.1442)\tMAE 6.119 (8.570)\n",
      "Epoch: [9][70/81]\tTime 0.029 (0.028)\tData 0.004 (0.003)\tLoss 69.1759 (215.2389)\tMAE 6.701 (8.581)\n",
      "Epoch: [9][80/81]\tTime 0.015 (0.028)\tData 0.001 (0.003)\tLoss 14.6570 (208.9617)\tMAE 2.951 (8.572)\n",
      "Epoch: [10][0/81]\tTime 0.032 (0.032)\tData 0.007 (0.007)\tLoss 61.1069 (61.1069)\tMAE 7.207 (7.207)\n",
      "Epoch: [10][10/81]\tTime 0.028 (0.028)\tData 0.004 (0.004)\tLoss 975.6170 (272.8632)\tMAE 11.226 (8.098)\n",
      "Epoch: [10][20/81]\tTime 0.027 (0.028)\tData 0.003 (0.003)\tLoss 99.6605 (243.1722)\tMAE 8.033 (8.383)\n",
      "Epoch: [10][30/81]\tTime 0.027 (0.028)\tData 0.004 (0.003)\tLoss 123.0566 (240.4170)\tMAE 8.779 (8.710)\n",
      "Epoch: [10][40/81]\tTime 0.025 (0.028)\tData 0.002 (0.003)\tLoss 162.8431 (228.9228)\tMAE 9.513 (8.756)\n",
      "Epoch: [10][50/81]\tTime 0.028 (0.028)\tData 0.004 (0.003)\tLoss 195.5748 (221.2601)\tMAE 9.144 (8.693)\n",
      "Epoch: [10][60/81]\tTime 0.028 (0.028)\tData 0.004 (0.003)\tLoss 67.1185 (199.1884)\tMAE 6.716 (8.417)\n",
      "Epoch: [10][70/81]\tTime 0.026 (0.028)\tData 0.002 (0.003)\tLoss 456.5649 (203.6340)\tMAE 10.497 (8.435)\n",
      "Epoch: [10][80/81]\tTime 0.012 (0.028)\tData 0.000 (0.003)\tLoss 41.8657 (208.9963)\tMAE 6.113 (8.520)\n",
      "Epoch: [11][0/81]\tTime 0.030 (0.030)\tData 0.003 (0.003)\tLoss 87.8010 (87.8010)\tMAE 7.346 (7.346)\n",
      "Epoch: [11][10/81]\tTime 0.028 (0.028)\tData 0.004 (0.003)\tLoss 236.1852 (263.7031)\tMAE 8.386 (8.343)\n",
      "Epoch: [11][20/81]\tTime 0.027 (0.028)\tData 0.002 (0.003)\tLoss 61.1016 (267.1207)\tMAE 6.460 (8.722)\n",
      "Epoch: [11][30/81]\tTime 0.029 (0.028)\tData 0.004 (0.003)\tLoss 119.1654 (246.0405)\tMAE 8.685 (8.750)\n",
      "Epoch: [11][40/81]\tTime 0.029 (0.028)\tData 0.004 (0.003)\tLoss 77.8130 (253.3579)\tMAE 7.416 (9.011)\n",
      "Epoch: [11][50/81]\tTime 0.026 (0.028)\tData 0.002 (0.003)\tLoss 239.5844 (249.2995)\tMAE 10.288 (9.081)\n",
      "Epoch: [11][60/81]\tTime 0.028 (0.028)\tData 0.004 (0.003)\tLoss 105.8607 (227.2371)\tMAE 7.190 (8.773)\n",
      "Epoch: [11][70/81]\tTime 0.027 (0.028)\tData 0.003 (0.003)\tLoss 62.6855 (218.3001)\tMAE 6.063 (8.659)\n",
      "Epoch: [11][80/81]\tTime 0.011 (0.028)\tData 0.000 (0.003)\tLoss 122.1995 (208.5680)\tMAE 10.536 (8.542)\n",
      "Epoch: [12][0/81]\tTime 0.028 (0.028)\tData 0.003 (0.003)\tLoss 731.8529 (731.8529)\tMAE 11.520 (11.520)\n",
      "Epoch: [12][10/81]\tTime 0.030 (0.028)\tData 0.004 (0.003)\tLoss 171.0122 (206.8352)\tMAE 9.604 (8.647)\n",
      "Epoch: [12][20/81]\tTime 0.027 (0.027)\tData 0.003 (0.003)\tLoss 46.9755 (213.6615)\tMAE 5.750 (8.767)\n",
      "Epoch: [12][30/81]\tTime 0.027 (0.028)\tData 0.004 (0.003)\tLoss 34.5799 (227.5334)\tMAE 5.638 (8.826)\n",
      "Epoch: [12][40/81]\tTime 0.028 (0.028)\tData 0.004 (0.003)\tLoss 312.3153 (227.8887)\tMAE 9.694 (8.759)\n",
      "Epoch: [12][50/81]\tTime 0.025 (0.028)\tData 0.002 (0.003)\tLoss 202.3181 (221.3456)\tMAE 9.245 (8.628)\n",
      "Epoch: [12][60/81]\tTime 0.035 (0.028)\tData 0.003 (0.003)\tLoss 68.6451 (215.3517)\tMAE 6.394 (8.439)\n",
      "Epoch: [12][70/81]\tTime 0.028 (0.028)\tData 0.003 (0.003)\tLoss 127.8672 (209.0542)\tMAE 9.267 (8.478)\n",
      "Epoch: [12][80/81]\tTime 0.012 (0.028)\tData 0.000 (0.003)\tLoss 36.5773 (208.6687)\tMAE 5.007 (8.542)\n",
      "Epoch: [13][0/81]\tTime 0.029 (0.029)\tData 0.003 (0.003)\tLoss 98.2478 (98.2478)\tMAE 7.961 (7.961)\n",
      "Epoch: [13][10/81]\tTime 0.027 (0.028)\tData 0.003 (0.003)\tLoss 353.1622 (349.6317)\tMAE 8.845 (9.599)\n",
      "Epoch: [13][20/81]\tTime 0.029 (0.028)\tData 0.003 (0.003)\tLoss 49.2402 (286.5685)\tMAE 6.566 (9.386)\n",
      "Epoch: [13][30/81]\tTime 0.028 (0.028)\tData 0.003 (0.003)\tLoss 186.9464 (257.5284)\tMAE 9.815 (9.359)\n",
      "Epoch: [13][40/81]\tTime 0.028 (0.028)\tData 0.003 (0.003)\tLoss 256.9629 (239.6090)\tMAE 9.806 (9.176)\n",
      "Epoch: [13][50/81]\tTime 0.029 (0.029)\tData 0.003 (0.003)\tLoss 72.4317 (228.3013)\tMAE 6.247 (8.812)\n",
      "Epoch: [13][60/81]\tTime 0.029 (0.029)\tData 0.003 (0.003)\tLoss 18.7273 (210.6008)\tMAE 3.879 (8.542)\n",
      "Epoch: [13][70/81]\tTime 0.030 (0.029)\tData 0.004 (0.003)\tLoss 325.8390 (211.3316)\tMAE 10.204 (8.552)\n",
      "Epoch: [13][80/81]\tTime 0.016 (0.029)\tData 0.001 (0.003)\tLoss 39.0240 (208.4572)\tMAE 6.583 (8.568)\n",
      "Epoch: [14][0/81]\tTime 0.030 (0.030)\tData 0.003 (0.003)\tLoss 1072.9475 (1072.9475)\tMAE 16.328 (16.328)\n",
      "Epoch: [14][10/81]\tTime 0.028 (0.029)\tData 0.003 (0.003)\tLoss 105.8826 (227.1960)\tMAE 7.191 (8.568)\n",
      "Epoch: [14][20/81]\tTime 0.028 (0.029)\tData 0.003 (0.003)\tLoss 57.2666 (231.3313)\tMAE 6.545 (8.484)\n",
      "Epoch: [14][30/81]\tTime 0.029 (0.029)\tData 0.003 (0.003)\tLoss 56.8943 (200.0198)\tMAE 6.303 (8.107)\n",
      "Epoch: [14][40/81]\tTime 0.029 (0.029)\tData 0.004 (0.003)\tLoss 146.0630 (205.3513)\tMAE 7.657 (8.208)\n",
      "Epoch: [14][50/81]\tTime 0.026 (0.029)\tData 0.003 (0.003)\tLoss 54.0857 (225.5961)\tMAE 6.694 (8.346)\n",
      "Epoch: [14][60/81]\tTime 0.030 (0.029)\tData 0.005 (0.003)\tLoss 466.7706 (214.3136)\tMAE 11.454 (8.355)\n",
      "Epoch: [14][70/81]\tTime 0.037 (0.029)\tData 0.008 (0.003)\tLoss 211.9325 (209.4474)\tMAE 8.665 (8.439)\n",
      "Epoch: [14][80/81]\tTime 0.019 (0.029)\tData 0.001 (0.004)\tLoss 35.7811 (208.5149)\tMAE 5.863 (8.513)\n",
      "Epoch: [15][0/81]\tTime 0.043 (0.043)\tData 0.003 (0.003)\tLoss 110.3392 (110.3392)\tMAE 8.081 (8.081)\n",
      "Epoch: [15][10/81]\tTime 0.041 (0.037)\tData 0.005 (0.006)\tLoss 114.1433 (149.9756)\tMAE 6.241 (7.885)\n",
      "Epoch: [15][20/81]\tTime 0.042 (0.035)\tData 0.006 (0.005)\tLoss 127.4469 (193.4975)\tMAE 8.610 (8.280)\n",
      "Epoch: [15][30/81]\tTime 0.027 (0.034)\tData 0.003 (0.005)\tLoss 130.2166 (188.0515)\tMAE 8.203 (8.488)\n",
      "Epoch: [15][40/81]\tTime 0.027 (0.033)\tData 0.003 (0.005)\tLoss 82.6796 (177.2207)\tMAE 7.494 (8.353)\n",
      "Epoch: [15][50/81]\tTime 0.029 (0.032)\tData 0.003 (0.005)\tLoss 129.8071 (183.1666)\tMAE 7.746 (8.308)\n",
      "Epoch: [15][60/81]\tTime 0.027 (0.031)\tData 0.003 (0.004)\tLoss 53.7215 (187.4841)\tMAE 6.809 (8.276)\n",
      "Epoch: [15][70/81]\tTime 0.049 (0.032)\tData 0.008 (0.004)\tLoss 64.7934 (204.4199)\tMAE 7.407 (8.499)\n",
      "Epoch: [15][80/81]\tTime 0.016 (0.031)\tData 0.001 (0.004)\tLoss 1057.3734 (209.1124)\tMAE 22.867 (8.572)\n",
      "Epoch: [16][0/81]\tTime 0.031 (0.031)\tData 0.004 (0.004)\tLoss 1046.2911 (1046.2911)\tMAE 16.305 (16.305)\n",
      "Epoch: [16][10/81]\tTime 0.030 (0.033)\tData 0.004 (0.006)\tLoss 260.3503 (286.4599)\tMAE 11.145 (10.217)\n",
      "Epoch: [16][20/81]\tTime 0.026 (0.030)\tData 0.002 (0.005)\tLoss 43.1463 (202.6544)\tMAE 6.223 (9.192)\n",
      "Epoch: [16][30/81]\tTime 0.029 (0.030)\tData 0.003 (0.004)\tLoss 110.3712 (204.1336)\tMAE 6.979 (9.076)\n",
      "Epoch: [16][40/81]\tTime 0.037 (0.030)\tData 0.008 (0.004)\tLoss 131.5727 (199.7101)\tMAE 8.144 (8.751)\n",
      "Epoch: [16][50/81]\tTime 0.045 (0.031)\tData 0.003 (0.004)\tLoss 208.9283 (212.4991)\tMAE 8.872 (8.705)\n",
      "Epoch: [16][60/81]\tTime 0.035 (0.031)\tData 0.003 (0.004)\tLoss 48.8340 (208.9637)\tMAE 6.192 (8.700)\n",
      "Epoch: [16][70/81]\tTime 0.027 (0.030)\tData 0.003 (0.004)\tLoss 897.0728 (214.3932)\tMAE 14.901 (8.706)\n",
      "Epoch: [16][80/81]\tTime 0.016 (0.031)\tData 0.001 (0.004)\tLoss 17.3613 (209.3073)\tMAE 3.977 (8.670)\n",
      "Epoch: [17][0/81]\tTime 0.034 (0.034)\tData 0.007 (0.007)\tLoss 113.0114 (113.0114)\tMAE 7.455 (7.455)\n",
      "Epoch: [17][10/81]\tTime 0.036 (0.036)\tData 0.007 (0.008)\tLoss 406.8985 (221.9107)\tMAE 9.369 (8.352)\n",
      "Epoch: [17][20/81]\tTime 0.034 (0.035)\tData 0.007 (0.008)\tLoss 140.3750 (211.6682)\tMAE 7.573 (8.106)\n",
      "Epoch: [17][30/81]\tTime 0.035 (0.035)\tData 0.008 (0.008)\tLoss 79.8147 (197.9570)\tMAE 6.946 (7.966)\n",
      "Epoch: [17][40/81]\tTime 0.035 (0.035)\tData 0.008 (0.008)\tLoss 395.1891 (197.5745)\tMAE 11.397 (8.184)\n",
      "Epoch: [17][50/81]\tTime 0.035 (0.035)\tData 0.008 (0.007)\tLoss 210.7283 (191.8479)\tMAE 9.175 (8.319)\n",
      "Epoch: [17][60/81]\tTime 0.027 (0.034)\tData 0.003 (0.007)\tLoss 70.3464 (198.6683)\tMAE 7.371 (8.476)\n",
      "Epoch: [17][70/81]\tTime 0.028 (0.033)\tData 0.004 (0.006)\tLoss 126.6416 (213.8934)\tMAE 8.821 (8.673)\n",
      "Epoch: [17][80/81]\tTime 0.011 (0.033)\tData 0.000 (0.006)\tLoss 28.1450 (208.5177)\tMAE 5.494 (8.562)\n",
      "Epoch: [18][0/81]\tTime 0.028 (0.028)\tData 0.003 (0.003)\tLoss 90.4840 (90.4840)\tMAE 7.223 (7.223)\n",
      "Epoch: [18][10/81]\tTime 0.026 (0.028)\tData 0.003 (0.003)\tLoss 37.8092 (167.5224)\tMAE 5.419 (7.834)\n",
      "Epoch: [18][20/81]\tTime 0.028 (0.028)\tData 0.004 (0.003)\tLoss 104.7862 (177.9976)\tMAE 8.069 (8.032)\n",
      "Epoch: [18][30/81]\tTime 0.027 (0.028)\tData 0.002 (0.003)\tLoss 1056.7715 (191.9620)\tMAE 13.353 (8.160)\n",
      "Epoch: [18][40/81]\tTime 0.044 (0.029)\tData 0.006 (0.003)\tLoss 78.9675 (191.5421)\tMAE 6.927 (8.116)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [18][50/81]\tTime 0.046 (0.032)\tData 0.007 (0.004)\tLoss 77.5545 (181.7351)\tMAE 7.183 (7.850)\n",
      "Epoch: [18][60/81]\tTime 0.046 (0.034)\tData 0.007 (0.004)\tLoss 370.9203 (194.4050)\tMAE 10.205 (8.089)\n",
      "Epoch: [18][70/81]\tTime 0.044 (0.036)\tData 0.006 (0.004)\tLoss 180.5419 (202.3884)\tMAE 10.103 (8.348)\n",
      "Epoch: [18][80/81]\tTime 0.021 (0.037)\tData 0.001 (0.005)\tLoss 45.7001 (209.0285)\tMAE 6.865 (8.512)\n",
      "Epoch: [19][0/81]\tTime 0.043 (0.043)\tData 0.004 (0.004)\tLoss 201.5094 (201.5094)\tMAE 10.990 (10.990)\n",
      "Epoch: [19][10/81]\tTime 0.043 (0.044)\tData 0.005 (0.006)\tLoss 82.0765 (220.7341)\tMAE 6.813 (8.951)\n",
      "Epoch: [19][20/81]\tTime 0.028 (0.041)\tData 0.003 (0.005)\tLoss 130.5147 (169.7037)\tMAE 8.739 (8.381)\n",
      "Epoch: [19][30/81]\tTime 0.028 (0.037)\tData 0.003 (0.005)\tLoss 68.5099 (178.9761)\tMAE 5.989 (8.157)\n",
      "Epoch: [19][40/81]\tTime 0.028 (0.035)\tData 0.003 (0.004)\tLoss 795.3002 (241.6773)\tMAE 13.948 (8.678)\n",
      "Epoch: [19][50/81]\tTime 0.028 (0.034)\tData 0.004 (0.004)\tLoss 39.9080 (217.1654)\tMAE 5.843 (8.626)\n",
      "Epoch: [19][60/81]\tTime 0.029 (0.033)\tData 0.003 (0.004)\tLoss 91.0879 (215.7132)\tMAE 7.471 (8.711)\n",
      "Epoch: [19][70/81]\tTime 0.027 (0.032)\tData 0.003 (0.004)\tLoss 235.6713 (207.6428)\tMAE 9.260 (8.524)\n",
      "Epoch: [19][80/81]\tTime 0.012 (0.031)\tData 0.000 (0.004)\tLoss 405.3737 (209.2659)\tMAE 13.068 (8.480)\n",
      "Epoch: [20][0/81]\tTime 0.028 (0.028)\tData 0.003 (0.003)\tLoss 88.0991 (88.0991)\tMAE 7.757 (7.757)\n",
      "Epoch: [20][10/81]\tTime 0.029 (0.028)\tData 0.004 (0.003)\tLoss 681.9255 (307.6175)\tMAE 11.324 (9.805)\n",
      "Epoch: [20][20/81]\tTime 0.030 (0.028)\tData 0.004 (0.003)\tLoss 191.0055 (227.7981)\tMAE 9.466 (9.360)\n",
      "Epoch: [20][30/81]\tTime 0.027 (0.028)\tData 0.004 (0.003)\tLoss 69.1817 (213.8579)\tMAE 6.763 (8.986)\n",
      "Epoch: [20][40/81]\tTime 0.030 (0.028)\tData 0.004 (0.003)\tLoss 63.7443 (197.2803)\tMAE 5.747 (8.652)\n",
      "Epoch: [20][50/81]\tTime 0.029 (0.028)\tData 0.003 (0.003)\tLoss 405.8177 (196.4894)\tMAE 9.412 (8.465)\n",
      "Epoch: [20][60/81]\tTime 0.031 (0.028)\tData 0.004 (0.003)\tLoss 372.1246 (190.3462)\tMAE 10.683 (8.426)\n",
      "Epoch: [20][70/81]\tTime 0.028 (0.028)\tData 0.004 (0.003)\tLoss 202.8246 (210.3636)\tMAE 8.560 (8.602)\n",
      "Epoch: [20][80/81]\tTime 0.013 (0.028)\tData 0.000 (0.003)\tLoss 34.7829 (208.9720)\tMAE 6.214 (8.671)\n",
      "Epoch: [21][0/81]\tTime 0.030 (0.030)\tData 0.003 (0.003)\tLoss 1467.4207 (1467.4207)\tMAE 18.804 (18.804)\n",
      "Epoch: [21][10/81]\tTime 0.029 (0.028)\tData 0.003 (0.003)\tLoss 123.8756 (297.2719)\tMAE 7.970 (9.650)\n",
      "Epoch: [21][20/81]\tTime 0.025 (0.028)\tData 0.002 (0.003)\tLoss 37.7242 (205.7826)\tMAE 6.061 (8.416)\n",
      "Epoch: [21][30/81]\tTime 0.028 (0.028)\tData 0.004 (0.003)\tLoss 51.4286 (209.5296)\tMAE 6.084 (8.304)\n",
      "Epoch: [21][40/81]\tTime 0.045 (0.031)\tData 0.006 (0.004)\tLoss 88.8766 (213.5141)\tMAE 7.779 (8.504)\n",
      "Epoch: [21][50/81]\tTime 0.044 (0.034)\tData 0.006 (0.004)\tLoss 51.4404 (216.6627)\tMAE 7.114 (8.685)\n",
      "Epoch: [21][60/81]\tTime 0.044 (0.036)\tData 0.006 (0.005)\tLoss 119.1503 (221.0714)\tMAE 8.716 (8.751)\n",
      "Epoch: [21][70/81]\tTime 0.047 (0.037)\tData 0.006 (0.005)\tLoss 58.6917 (218.6919)\tMAE 5.901 (8.678)\n",
      "Epoch: [21][80/81]\tTime 0.021 (0.037)\tData 0.001 (0.005)\tLoss 42.4087 (208.9510)\tMAE 6.488 (8.527)\n",
      "Epoch: [22][0/81]\tTime 0.043 (0.043)\tData 0.004 (0.004)\tLoss 162.1269 (162.1269)\tMAE 7.176 (7.176)\n",
      "Epoch: [22][10/81]\tTime 0.047 (0.045)\tData 0.006 (0.006)\tLoss 147.2077 (131.6815)\tMAE 8.056 (7.329)\n",
      "Epoch: [22][20/81]\tTime 0.046 (0.045)\tData 0.006 (0.006)\tLoss 804.6176 (190.0912)\tMAE 12.450 (7.859)\n",
      "Epoch: [22][30/81]\tTime 0.045 (0.045)\tData 0.007 (0.006)\tLoss 81.9287 (261.2698)\tMAE 8.276 (8.912)\n",
      "Epoch: [22][40/81]\tTime 0.044 (0.045)\tData 0.006 (0.006)\tLoss 81.0340 (236.7197)\tMAE 8.179 (9.016)\n",
      "Epoch: [22][50/81]\tTime 0.026 (0.044)\tData 0.003 (0.006)\tLoss 69.4923 (225.1940)\tMAE 7.091 (8.909)\n",
      "Epoch: [22][60/81]\tTime 0.028 (0.041)\tData 0.003 (0.005)\tLoss 51.0378 (220.9649)\tMAE 6.115 (8.714)\n",
      "Epoch: [22][70/81]\tTime 0.027 (0.039)\tData 0.003 (0.005)\tLoss 146.8055 (203.8961)\tMAE 7.809 (8.457)\n",
      "Epoch: [22][80/81]\tTime 0.016 (0.039)\tData 0.001 (0.005)\tLoss 35.0489 (208.9154)\tMAE 6.196 (8.505)\n",
      "Epoch: [23][0/81]\tTime 0.035 (0.035)\tData 0.007 (0.007)\tLoss 103.6447 (103.6447)\tMAE 7.995 (7.995)\n",
      "Epoch: [23][10/81]\tTime 0.028 (0.034)\tData 0.003 (0.006)\tLoss 139.7112 (203.1230)\tMAE 8.276 (8.488)\n",
      "Epoch: [23][20/81]\tTime 0.029 (0.031)\tData 0.004 (0.005)\tLoss 220.6451 (216.4399)\tMAE 9.849 (8.788)\n",
      "Epoch: [23][30/81]\tTime 0.028 (0.030)\tData 0.004 (0.004)\tLoss 65.1566 (215.9730)\tMAE 6.940 (8.740)\n",
      "Epoch: [23][40/81]\tTime 0.025 (0.029)\tData 0.003 (0.004)\tLoss 75.7546 (197.2818)\tMAE 6.978 (8.456)\n",
      "Epoch: [23][50/81]\tTime 0.028 (0.029)\tData 0.004 (0.004)\tLoss 106.1366 (213.9657)\tMAE 7.849 (8.631)\n",
      "Epoch: [23][60/81]\tTime 0.028 (0.029)\tData 0.004 (0.004)\tLoss 185.2165 (200.6840)\tMAE 8.877 (8.537)\n",
      "Epoch: [23][70/81]\tTime 0.027 (0.029)\tData 0.002 (0.004)\tLoss 74.1272 (214.7767)\tMAE 7.101 (8.642)\n",
      "Epoch: [23][80/81]\tTime 0.011 (0.028)\tData 0.000 (0.004)\tLoss 223.3835 (208.6323)\tMAE 10.953 (8.583)\n",
      "Epoch: [24][0/81]\tTime 0.028 (0.028)\tData 0.003 (0.003)\tLoss 682.0109 (682.0109)\tMAE 10.354 (10.354)\n",
      "Epoch: [24][10/81]\tTime 0.027 (0.027)\tData 0.004 (0.003)\tLoss 126.1742 (171.1551)\tMAE 8.635 (7.955)\n",
      "Epoch: [24][20/81]\tTime 0.026 (0.027)\tData 0.002 (0.003)\tLoss 38.3430 (219.7505)\tMAE 5.936 (8.567)\n",
      "Epoch: [24][30/81]\tTime 0.027 (0.028)\tData 0.004 (0.003)\tLoss 76.9863 (214.2011)\tMAE 7.320 (8.672)\n",
      "Epoch: [24][40/81]\tTime 0.028 (0.028)\tData 0.003 (0.003)\tLoss 81.9997 (227.8689)\tMAE 7.363 (8.712)\n",
      "Epoch: [24][50/81]\tTime 0.028 (0.028)\tData 0.004 (0.003)\tLoss 71.9790 (223.5584)\tMAE 6.464 (8.710)\n",
      "Epoch: [24][60/81]\tTime 0.036 (0.028)\tData 0.009 (0.003)\tLoss 138.4651 (217.9650)\tMAE 9.037 (8.706)\n",
      "Epoch: [24][70/81]\tTime 0.028 (0.028)\tData 0.004 (0.003)\tLoss 50.4692 (205.9344)\tMAE 5.891 (8.562)\n",
      "Epoch: [24][80/81]\tTime 0.012 (0.028)\tData 0.000 (0.003)\tLoss 33.4432 (208.5912)\tMAE 5.856 (8.571)\n",
      "Epoch: [25][0/81]\tTime 0.029 (0.029)\tData 0.003 (0.003)\tLoss 809.9470 (809.9470)\tMAE 12.854 (12.854)\n",
      "Epoch: [25][10/81]\tTime 0.026 (0.028)\tData 0.003 (0.003)\tLoss 31.8432 (238.7728)\tMAE 5.442 (8.557)\n",
      "Epoch: [25][20/81]\tTime 0.026 (0.028)\tData 0.002 (0.003)\tLoss 296.0077 (214.4001)\tMAE 8.337 (8.418)\n",
      "Epoch: [25][30/81]\tTime 0.027 (0.028)\tData 0.004 (0.003)\tLoss 81.3567 (272.7430)\tMAE 8.258 (9.113)\n",
      "Epoch: [25][40/81]\tTime 0.026 (0.028)\tData 0.002 (0.003)\tLoss 80.1906 (273.5781)\tMAE 8.661 (9.535)\n",
      "Epoch: [25][50/81]\tTime 0.028 (0.028)\tData 0.004 (0.003)\tLoss 73.5302 (260.3983)\tMAE 6.838 (9.528)\n",
      "Epoch: [25][60/81]\tTime 0.028 (0.028)\tData 0.003 (0.003)\tLoss 100.1537 (240.1875)\tMAE 7.281 (9.098)\n",
      "Epoch: [25][70/81]\tTime 0.028 (0.028)\tData 0.004 (0.003)\tLoss 66.9711 (218.7194)\tMAE 6.553 (8.728)\n",
      "Epoch: [25][80/81]\tTime 0.012 (0.028)\tData 0.000 (0.003)\tLoss 22.4505 (208.6019)\tMAE 4.666 (8.523)\n",
      "Epoch: [26][0/81]\tTime 0.028 (0.028)\tData 0.003 (0.003)\tLoss 64.8170 (64.8170)\tMAE 6.660 (6.660)\n",
      "Epoch: [26][10/81]\tTime 0.029 (0.028)\tData 0.005 (0.003)\tLoss 349.0919 (207.2421)\tMAE 11.213 (8.451)\n",
      "Epoch: [26][20/81]\tTime 0.025 (0.027)\tData 0.003 (0.003)\tLoss 65.4228 (178.5992)\tMAE 6.651 (8.194)\n",
      "Epoch: [26][30/81]\tTime 0.028 (0.028)\tData 0.004 (0.003)\tLoss 23.4895 (181.5323)\tMAE 4.668 (7.968)\n",
      "Epoch: [26][40/81]\tTime 0.027 (0.028)\tData 0.002 (0.003)\tLoss 485.1441 (181.6242)\tMAE 8.960 (7.843)\n",
      "Epoch: [26][50/81]\tTime 0.027 (0.028)\tData 0.003 (0.003)\tLoss 690.1859 (203.9033)\tMAE 11.646 (8.197)\n",
      "Epoch: [26][60/81]\tTime 0.028 (0.028)\tData 0.004 (0.003)\tLoss 66.4863 (218.0058)\tMAE 7.250 (8.489)\n",
      "Epoch: [26][70/81]\tTime 0.029 (0.028)\tData 0.004 (0.003)\tLoss 181.2245 (219.1856)\tMAE 9.151 (8.715)\n",
      "Epoch: [26][80/81]\tTime 0.013 (0.027)\tData 0.000 (0.003)\tLoss 21.2987 (208.7573)\tMAE 4.164 (8.628)\n",
      "Epoch: [27][0/81]\tTime 0.028 (0.028)\tData 0.003 (0.003)\tLoss 116.9435 (116.9435)\tMAE 8.161 (8.161)\n",
      "Epoch: [27][10/81]\tTime 0.027 (0.028)\tData 0.004 (0.003)\tLoss 91.7679 (204.5468)\tMAE 7.002 (8.619)\n",
      "Epoch: [27][20/81]\tTime 0.028 (0.028)\tData 0.004 (0.003)\tLoss 270.8657 (180.5103)\tMAE 10.078 (8.504)\n",
      "Epoch: [27][30/81]\tTime 0.027 (0.028)\tData 0.004 (0.003)\tLoss 31.8915 (171.2309)\tMAE 5.534 (8.274)\n",
      "Epoch: [27][40/81]\tTime 0.027 (0.028)\tData 0.003 (0.003)\tLoss 29.7412 (166.7813)\tMAE 5.063 (8.047)\n",
      "Epoch: [27][50/81]\tTime 0.029 (0.028)\tData 0.003 (0.003)\tLoss 284.8346 (173.4401)\tMAE 8.675 (8.057)\n",
      "Epoch: [27][60/81]\tTime 0.026 (0.028)\tData 0.002 (0.003)\tLoss 52.3062 (174.4215)\tMAE 6.787 (8.004)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [27][70/81]\tTime 0.028 (0.028)\tData 0.005 (0.003)\tLoss 105.5180 (200.1400)\tMAE 8.583 (8.265)\n",
      "Epoch: [27][80/81]\tTime 0.012 (0.028)\tData 0.001 (0.003)\tLoss 80.2305 (209.0289)\tMAE 8.768 (8.451)\n",
      "Epoch: [28][0/81]\tTime 0.028 (0.028)\tData 0.003 (0.003)\tLoss 45.1594 (45.1594)\tMAE 6.211 (6.211)\n",
      "Epoch: [28][10/81]\tTime 0.027 (0.028)\tData 0.003 (0.003)\tLoss 64.2323 (202.4523)\tMAE 7.341 (8.424)\n",
      "Epoch: [28][20/81]\tTime 0.028 (0.028)\tData 0.004 (0.003)\tLoss 45.6930 (165.2651)\tMAE 5.133 (7.828)\n",
      "Epoch: [28][30/81]\tTime 0.029 (0.028)\tData 0.004 (0.003)\tLoss 59.4269 (214.3228)\tMAE 5.373 (8.185)\n",
      "Epoch: [28][40/81]\tTime 0.028 (0.028)\tData 0.004 (0.003)\tLoss 64.4654 (222.7620)\tMAE 7.330 (8.508)\n",
      "Epoch: [28][50/81]\tTime 0.028 (0.028)\tData 0.004 (0.003)\tLoss 68.5428 (223.6215)\tMAE 7.604 (8.675)\n",
      "Epoch: [28][60/81]\tTime 0.026 (0.028)\tData 0.002 (0.003)\tLoss 42.6693 (222.1105)\tMAE 5.877 (8.717)\n",
      "Epoch: [28][70/81]\tTime 0.026 (0.028)\tData 0.002 (0.003)\tLoss 113.0743 (211.2635)\tMAE 8.278 (8.631)\n",
      "Epoch: [28][80/81]\tTime 0.012 (0.028)\tData 0.000 (0.003)\tLoss 329.1354 (209.2566)\tMAE 13.174 (8.575)\n",
      "Epoch: [29][0/81]\tTime 0.029 (0.029)\tData 0.003 (0.003)\tLoss 281.1341 (281.1341)\tMAE 10.033 (10.033)\n",
      "Epoch: [29][10/81]\tTime 0.028 (0.028)\tData 0.004 (0.003)\tLoss 141.7232 (251.0974)\tMAE 9.231 (10.093)\n",
      "Epoch: [29][20/81]\tTime 0.028 (0.028)\tData 0.003 (0.003)\tLoss 132.0541 (310.3327)\tMAE 8.993 (10.581)\n",
      "Epoch: [29][30/81]\tTime 0.028 (0.028)\tData 0.003 (0.003)\tLoss 281.5354 (289.1030)\tMAE 10.966 (10.485)\n",
      "Epoch: [29][40/81]\tTime 0.027 (0.028)\tData 0.003 (0.003)\tLoss 147.2412 (247.4940)\tMAE 6.750 (9.735)\n",
      "Epoch: [29][50/81]\tTime 0.029 (0.028)\tData 0.003 (0.003)\tLoss 47.1516 (216.4508)\tMAE 5.129 (9.029)\n",
      "Epoch: [29][60/81]\tTime 0.025 (0.028)\tData 0.003 (0.003)\tLoss 87.0101 (219.2909)\tMAE 6.396 (8.735)\n",
      "Epoch: [29][70/81]\tTime 0.032 (0.028)\tData 0.007 (0.003)\tLoss 53.7938 (201.8652)\tMAE 6.631 (8.498)\n",
      "Epoch: [29][80/81]\tTime 0.012 (0.028)\tData 0.000 (0.003)\tLoss 99.8764 (208.5740)\tMAE 9.370 (8.603)\n"
     ]
    }
   ],
   "source": [
    "scheduler = MultiStepLR(optimizer, milestones=lr_milestones,\n",
    "                        gamma=0.1)\n",
    "\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    # train for one epoch\n",
    "    train(train_loader, mixnet, modelCG, modelOFM, criterion, optimizer, epoch, normalizer)\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
