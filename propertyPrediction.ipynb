{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from random import sample\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn import metrics\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "# from cgcnn.data import CIFData\n",
    "# from cgcnn.data import collate_pool, get_train_val_test_loader\n",
    "from cgcnn.featureModel import CrystalGraphConvNet\n",
    "from property_prediction_ofm.model import Net\n",
    "\n",
    "from dataloader import CIFOFMData\n",
    "from dataloader import collate_pool, get_train_val_test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class MixtureNet(nn.Module):\n",
    "    def __init__(self, input_size=64):\n",
    "        super(MixtureNet, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, 48)\n",
    "        self.fc2 = nn.Linear(48, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MixtureNet(\n",
       "  (fc1): Linear(in_features=64, out_features=48, bias=True)\n",
       "  (fc2): Linear(in_features=48, out_features=32, bias=True)\n",
       "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixnet = MixtureNet()\n",
    "mixnet = mixnet.float()\n",
    "mixnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_options = '../project_mlns/dataset/'\n",
    "modelpathCG = 'trained_nets/formation-energy-per-atom.pth.tar'\n",
    "modelpathOFM = 'trained_nets/propertyPredictionUsingOFM_net.pth'\n",
    "\n",
    "workers = 0\n",
    "epochs = 30\n",
    "start_epoch = 0\n",
    "batch_size = 32\n",
    "lr = 0.01\n",
    "lr_milestones = [100]\n",
    "disable_cuda = False\n",
    "\n",
    "momentum = 0.9\n",
    "weight_decay = 0\n",
    "print_freq = 10\n",
    "\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "optim_type ='SGD'\n",
    "\n",
    "cuda = not disable_cuda and torch.cuda.is_available()\n",
    "\n",
    "best_mae_error = 1e10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] train_ratio is None, using all training data.\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "dataset = CIFOFMData(data_options)\n",
    "collate_fn = collate_pool\n",
    "train_loader, val_loader, test_loader = get_train_val_test_loader(\n",
    "    dataset=dataset,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=cuda,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=workers,\n",
    "    train_size = None,\n",
    "    test_size = None,\n",
    "    val_size = None,\n",
    "    val_ratio=val_ratio,\n",
    "    test_ratio=test_ratio,\n",
    "    return_test=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalizer(object):\n",
    "    \"\"\"Normalize a Tensor and restore it later. \"\"\"\n",
    "\n",
    "    def __init__(self, tensor):\n",
    "        \"\"\"tensor is taken as a sample to calculate the mean and std\"\"\"\n",
    "        self.mean = torch.mean(tensor)\n",
    "        self.std = torch.std(tensor)\n",
    "\n",
    "    def norm(self, tensor):\n",
    "        return (tensor - self.mean) / self.std\n",
    "\n",
    "    def denorm(self, normed_tensor):\n",
    "        return normed_tensor * self.std + self.mean\n",
    "\n",
    "    def state_dict(self):\n",
    "        return {'mean': self.mean,\n",
    "                'std': self.std}\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.mean = state_dict['mean']\n",
    "        self.std = state_dict['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(dataset) < 500:\n",
    "    warnings.warn('Dataset has less than 500 data points. '\n",
    "                  'Lower accuracy is expected. ')\n",
    "    sample_data_list = [dataset[i] for i in range(len(dataset))]\n",
    "else:\n",
    "    sample_data_list = [dataset[i] for i in\n",
    "                        sample(range(len(dataset)), 500)]\n",
    "_, sample_target, _, _ = collate_pool(sample_data_list)\n",
    "normalizer = Normalizer(sample_target)\n",
    "\n",
    "# build models\n",
    "structures, _, _, _ = dataset[0]\n",
    "orig_atom_fea_len = structures[0].shape[-1]\n",
    "nbr_fea_len = structures[1].shape[-1]\n",
    "\n",
    "model_checkpoint = torch.load(modelpathCG,\n",
    "                              map_location=lambda storage, loc: storage)\n",
    "model_args = argparse.Namespace(**model_checkpoint['args'])\n",
    "modelCG = CrystalGraphConvNet(orig_atom_fea_len, nbr_fea_len,\n",
    "                            atom_fea_len=model_args.atom_fea_len,\n",
    "                            n_conv=model_args.n_conv,\n",
    "                            h_fea_len=model_args.h_fea_len,\n",
    "                            n_h=model_args.n_h,\n",
    "                            classification=False)\n",
    "\n",
    "modelOFM = Net()\n",
    "modelOFM.load_state_dict(torch.load(modelpathOFM))\n",
    "\n",
    "if cuda:\n",
    "    modelOFM.cuda()\n",
    "    modelCG.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss func and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "if optim_type == 'SGD':\n",
    "    optimizer = optim.SGD(mixnet.parameters(), lr,\n",
    "                          momentum=momentum,\n",
    "                          weight_decay=weight_decay)\n",
    "elif optim_type == 'Adam':\n",
    "    optimizer = optim.Adam(mixnet.parameters(), lr,\n",
    "                           weight_decay=weight_decay)\n",
    "else:\n",
    "    raise NameError('Only SGD or Adam is allowed as --optim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resume from a checkpoint\n",
    "checkpointCG = torch.load(modelpathCG)\n",
    "modelCG.load_state_dict(checkpointCG['state_dict'])\n",
    "normalizer.load_state_dict(checkpointCG['normalizer'])\n",
    "\n",
    "checkpointOFM = torch.load(modelpathOFM)\n",
    "modelOFM.load_state_dict(checkpointOFM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(prediction, target):\n",
    "    \"\"\"\n",
    "    Computes the mean absolute error between prediction and target\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    prediction: torch.Tensor (N, 1)\n",
    "    target: torch.Tensor (N, 1)\n",
    "    \"\"\"\n",
    "    return torch.mean(torch.abs(target - prediction))\n",
    "\n",
    "\n",
    "def class_eval(prediction, target):\n",
    "    prediction = np.exp(prediction.numpy())\n",
    "    target = target.numpy()\n",
    "    pred_label = np.argmax(prediction, axis=1)\n",
    "    target_label = np.squeeze(target)\n",
    "    if not target_label.shape:\n",
    "        target_label = np.asarray([target_label])\n",
    "    if prediction.shape[1] == 2:\n",
    "        precision, recall, fscore, _ = metrics.precision_recall_fscore_support(\n",
    "            target_label, pred_label, average='binary')\n",
    "        auc_score = metrics.roc_auc_score(target_label, prediction[:, 1])\n",
    "        accuracy = metrics.accuracy_score(target_label, pred_label)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return accuracy, precision, recall, fscore, auc_score\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, k):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every k epochs\"\"\"\n",
    "    assert type(k) is int\n",
    "    lr = args.lr * (0.1 ** (epoch // k))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, mixnet, modelCG, modelOFM, criterion, optimizer, epoch, normalizer):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    mae_errors = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    mixnet.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target, _, ofmMat) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if cuda:\n",
    "            input_var = (Variable(input[0].cuda(non_blocking=True)),\n",
    "                         Variable(input[1].cuda(non_blocking=True)),\n",
    "                         input[2].cuda(non_blocking=True),\n",
    "                         [crys_idx.cuda(non_blocking=True) for crys_idx in input[3]])\n",
    "            inOfmMat = ofmMat.float().cuda(non_blocking=True)\n",
    "        else:\n",
    "            input_var = (Variable(input[0]),\n",
    "                         Variable(input[1]),\n",
    "                         input[2],\n",
    "                         input[3])\n",
    "            inOfmMat = ofmMat.float()\n",
    "            \n",
    "        # normalize target\n",
    "        target_normed = normalizer.norm(target)\n",
    "        \n",
    "        if cuda:\n",
    "            target_var = Variable(target_normed.cuda(non_blocking=True))\n",
    "        else:\n",
    "            target_var = Variable(target_normed)\n",
    "\n",
    "        # compute feature from CG and OFM models\n",
    "        featureCG = modelCG(*input_var)\n",
    "        featureOFM = modelOFM(inOfmMat)\n",
    "        # print(featureCG.size(), featureOFM.size())   \n",
    "        # final feature after concatenation of features from CG and OFM models\n",
    "        feature = torch.cat((featureCG, featureOFM), 1)\n",
    "        # print(feature.size())\n",
    "        MAE = min_mae\n",
    "        output = mixnet(feature)\n",
    "        \n",
    "        loss = criterion(output, target_var)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        mae_error = mae(normalizer.denorm(output.data.cpu()), target)\n",
    "        losses.update(loss.data.cpu(), target.size(0))\n",
    "        mae_errors.update(mae_error, target.size(0))\n",
    "       \n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "#         if i % print_freq == 0:\n",
    "#             print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "#                   'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "#                   'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "#                   'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "#                   'MAE {mae_errors.val:.3f} ({mae_errors.avg:.3f})'.format(\n",
    "#                 epoch, i, len(train_loader), batch_time=batch_time,\n",
    "#                 data_time=data_time, loss=losses, mae_errors=mae_errors)\n",
    "#             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final MAE: 0.041\n"
     ]
    }
   ],
   "source": [
    "scheduler = MultiStepLR(optimizer, milestones=lr_milestones,\n",
    "                        gamma=0.1)\n",
    "\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    # train for one epoch\n",
    "    train(train_loader, mixnet, modelCG, modelOFM, criterion, optimizer, epoch, normalizer)\n",
    "\n",
    "    scheduler.step()\n",
    "print(\"Final MAE: {}\".format(MAE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
